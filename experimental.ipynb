{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsite_urls(domain_url, max_subsites=1000):\n",
    "    # Initialize a set to store unique subsite URLs\n",
    "    subsites = set()\n",
    "\n",
    "    try:\n",
    "        # Fetch the content of the main page\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(domain_url, headers = headers)\n",
    "        print(response)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "\n",
    "        # Parse the content with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all anchor tags with href attributes\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            # Create absolute URLs from relative paths\n",
    "            subsite_url = urljoin(domain_url, link['href'])\n",
    "            # Parse the URL to ensure it's within the same domain\n",
    "            if urlparse(subsite_url).netloc == urlparse(domain_url).netloc:\n",
    "                subsites.add(subsite_url)\n",
    "\n",
    "            # Break if we have collected the desired number of subsites\n",
    "            if len(subsites) >= max_subsites:\n",
    "                break\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return list(subsites)\n",
    "\n",
    "def save_urls_to_file(urls, filename='subsites.txt'):\n",
    "    with open(filename, 'w') as file: #The with statement ensures that the file is properly closed after writing.\n",
    "        for url in urls:\n",
    "            file.write(url + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "domain_url = ['https://www.101cookbooks.com/',\n",
    "'https://www.allrecipes.com/',\n",
    "'https://www.ambitiouskitchen.com/',\n",
    "'https://www.averiecooks.com/',\n",
    "'https://www.bbc.co.uk/',\n",
    "'https://www.bbcgoodfood.com/',\n",
    "'https://www.bonappetit.com/',\n",
    "'https://www.budgetbytes.com/',\n",
    "'https://www.centraltexasfoodbank.org/',\n",
    "'https://www.closetcooking.com/',\n",
    "'https://cookieandkate.com/',\n",
    "'https://copykat.com/',\n",
    "#'https://damndelicious.net/',\n",
    "'https://www.eatingwell.com/',\n",
    "'https://www.epicurious.com/',\n",
    "'https://www.food.com/',\n",
    "'https://www.foodandwine.com/',\n",
    "#'https://www.foodnetwork.com/',\n",
    "'https://gimmedelicious.com/',\n",
    "'https://www.gimmesomeoven.com/',\n",
    "'https://julieblanner.com/',\n",
    "'https://www.kitchenstories.com/',\n",
    "'https://www.melskitchencafe.com/',\n",
    "'https://www.minimalistbaker.com/',\n",
    "'https://www.myrecipes.com/',\n",
    "'https://www.nomnompaleo.com/',\n",
    "'https://www.omnivorescookbook.com/',\n",
    "'https://pinchofyum.com/',\n",
    "'https://recipetineats.com/',\n",
    "'https://www.seriouseats.com/',\n",
    "'https://www.simplyrecipes.com/',\n",
    "'https://smittenkitchen.com/',\n",
    "'https://thepioneerwoman.com/',\n",
    "'https://www.tasteofhome.com/',\n",
    "'https://tastesbetterfromscratch.com/',\n",
    "'https://thatlowcarblife.com/',\n",
    "'https://www.theblackpeppercorn.com/',\n",
    "'https://therealfoodrds.com/',\n",
    "'https://www.thespruceeats.com/',\n",
    "'https://whatsgabycooking.com/',\n",
    "'https://www.woolworths.com.au/',\n",
    "'https://www.yummly.com/',\n",
    "'https://www.jamieoliver.com/'\n",
    "]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "subsite_urls = []\n",
    "for url in domain_url:\n",
    "    subsite_urls.append(get_subsite_urls(url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_f = [item for sublist in subsite_urls for item in sublist]\n",
    "save_urls_to_file(urls_f, 'subsites.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cookpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
